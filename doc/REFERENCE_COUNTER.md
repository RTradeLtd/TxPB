# Reference Counter

TemporalX uses a novel reference counter designed to work with IPFS Content Identifiers (CIDs). We use this in place of a pinning system like that used by `js-ipfs` and `go-ipfs`, which allows us to realize significant performance and efficiency gains.

The reference counter is implemented as a reference counter blockstore, which satisfies the IPFS blockstore interface. It intercepts all `Put`, `PutMany` and `Delete` calls and processes the block, while forwarding the request down the processing chain. `Delete` calls are handled a little differently, and the request is not actually forwarded down the procesisng chain. We use `Delete` calls as a "dereference" operation, that decreases the reference count of the block in question.

One of the really awesome features about our reference counter unlike the pinning system used by `go-ipfs` is that it is *non-blocking* unless you are doing a garbage collection run! If you want to see just how much faster our non-blocking reference counter is, check out our [benchmark blog post](https://medium.com/temporal-cloud/temporalx-vs-go-ipfs-official-node-benchmarks-8457037a77cf).

In order to permanently remove blocks that have a reference count of 0, you must trigger a garbage collection using TemporalX's admin api. The admin api is only enabled when using the reference counted blockstore, and is exposed on `localhost:9999` by default.  When you trigger a garbage collection, all blockstore interaction calls are blocked, while we wait for pending reference count operations to complete. Once all pending reference count operations have finished, we look for any unferenced blocks. These blocks are then subsequently permanently removed. After removing all unreferenced blocks, we resume normal operation and unblock all blockstore interaction calls.

# Why You Shouldn't Use A Cached Blockstore

When using the reference counter, if you want truly accurate results, it is advisable that you do not enable blockstore caching which requires explicit configuration to be enabled. Because the cached blockstore sits ontop of the reference counter blockstore, it will intercept the calls before our reference counter does. This means that more often than not, the calls won't bubble down through to our reference counted blockstore if the caching layer has the block. The effecct of this is that unless you get a cache miss, the maximum reference count will only ever be 1. 

Realistically a cached blockstore won't really reduce a lot of overhead, because the overhead of TemporalX is already so low, that you will get marginal performance gains. If you really want caching, it is advisable that you use datastore level caching through something like our badger datastore, which uses version 2 of the badger codebase, which has extensive caching features. This will ensure that you get the benefits of caching, while getting totally accurate reference count information.